#!/usr/bin/env python3
""" DESCRIPTION """
#In rucio config (so that cms regexes can be used)
#[policy]
#schema = cms

import os
import sys
import ssl
import json
import shlex
import argparse
import subprocess
import http.client
import logging

from jsonschema import validate

from rucio.client.didclient import DIDClient
from rucio.client.rseclient import RSEClient
from rucio.common.exception import DataIdentifierNotFound
from rucio.common.schema import get_schema_value
from rucio.common.config import config_get, config_get_int, config_get_bool

class Error(Exception):
    """Base class for other exceptions"""

class XrdPfcException(Error):
    """Raised when the xrd pfc json load fails"""

class XCacheReportException(Error):
    """Raised if some error happens in this plugin """

class XCacheArgsException(Error):
    """ Raised if some args are unsupported, not valid """

# =================================================================
#                     RUCIO Specific
# =================================================================
class RucioAPI():
    """ Rucio APIs """
    def __init__(self, args, logger):
        self.rseClient = RSEClient()
        self.didClient = DIDClient()
        self.args = args
        self.logger = logger

    def get_file_metadata(self, fInfo):
        """ Get file metadata info from Rucio """
        metadata = {'adler32': '00000001', 'bytes': fInfo['bytes']}
        if self.args.dryrun:
            self.logger.debug("[DRYRUN]. Return dummy metadata info for file %s. Return %s.",
                              fInfo['filename'], metadata)
            return metadata

        try:
            metadata = self.didClient.get_metadata(self.args.vo, fInfo['lfn'])
        except DataIdentifierNotFound as ex:
            err = "%s:%s not found in rucio catalog" % (self.args.vo, fInfo['lfn'])
            self.logger.debug(err)
            raise DataIdentifierNotFound from ex
        self.logger.debug("Got file %s metadata info from Rucio. Return %s.", fInfo, metadata)
        return metadata

    def validate_files(self, files):
        """ validate files metadata and return
            dictionary with good or bad files."""
        out = {"GOOD": [], "BAD": []}
        for fName, fDict in files.items():
            # In case rucio adler was used for finding file adler32, we already have metadata
            # inside allFilesInfo dict.
            # Otherwise - it will query rucio and compare adler32 and file size
            if 'metadata' in fDict and fDict['metadata']:
                metadata = fDict['metadata']
            else:
                try:
                    metadata = self.get_file_metadata(fDict)
                except DataIdentifierNotFound as ex:
                    # No such file in Rucio. Add it to BAD list
                    fDict['err_msg'] = str(ex)
                    out["BAD"].append(fDict)
                    continue
            if 'bytes' not in metadata and 'adler32' not in metadata:
                msg = 'Metadata info from Rucio did not returned bytes, and adler32 keys. Metadata out: %s' % metadata
                self.logger.debug(msg)
                fDict['err_msg'] = err
                out["BAD"].append(fDict)
            elif int(metadata["bytes"]) != int(fDict["bytes"]) or metadata["adler32"] != fDict["adler32"]:
                err = """%s:%s(bytes:%s, adler32:%s) has different size \
                         or checksum with metadata(bytes:%s, adler32:%s)""" % \
                         (self.args.vo, fName, fDict["bytes"],
                          fDict["adler32"], metadata["bytes"], metadata["adler32"])
                fDict['err_msg'] = err
                out["BAD"].append(fDict)
            else:
                out["GOOD"].append(fDict)
        return out

    def validate_rse(self, rse):
        """ validate rse"""
        # the rse must be volatile
        try:
            rse_attributes = self.rseClient.get_rse(rse)
        except Exception as ex:
            self.logger.error("Received exception from getting rse info. Exception: %s", ex)
            raise Exception from ex
        if not rse_attributes["volatile"]:
            err = "%s volatile is not True, Rucio Cache should not update it." % (rse)
            self.logger.error(err)
            raise Exception(err)

    def validate_payload(self, payload):
        """ Validate payload so it's schema is correct """
        validate(payload, get_schema_value('MESSAGE_OPERATION'))
        self.validate_rse(payload["rse"])
        if payload["operation"] == "add_replicas":
            validate(payload, get_schema_value('CACHE_ADD_REPLICAS'))
        else:
            validate(payload, get_schema_value('CACHE_DELETE_REPLICAS'))

# =================================================================
#                     Cache dir listing worker
# =================================================================
LOG_LEVELS = {'FATAL': logging.FATAL,
              'ERROR': logging.ERROR,
              'WARNING': logging.WARNING,
              'INFO': logging.INFO,
              'DEBUG': logging.DEBUG}

def getLogger(logLevel='DEBUG', streamLogging=False, logFile='api.log', rotate='1d', backups=5):
    """Get Stream Logger."""
    logger = logging.getLogger()
    handler = None
    if streamLogging:
        handler = logging.StreamHandler()
    else:
        handler = logging.handlers.TimedRotatingFileHandler(logFile, when=rotate, backupCount=backups)
    formatter = logging.Formatter("%(asctime)s.%(msecs)03d - %(name)s - %(levelname)s - %(message)s",
                                  datefmt="%a, %d %b %Y %H:%M:%S")
    handler.setFormatter(formatter)
    if not logger.handlers:
        logger.addHandler(handler)
    logger.setLevel(LOG_LEVELS[logLevel])
    return logger


class CacheWorker():
    """ Cache Scanner, Reporter """
    def __init__(self, args, logger=None):
        self.logger = logger if logger else getLogger(args.debug, True)
        self.args = args
        self.rucio = RucioAPI(args, self.logger)
        self.fileOut = {}
        self.allfiles = {}
        # In case debug mode and not dry run, enable http debug level.
        if self.args.debug == 'DEBUG' and not self.args.dryrun:
            http.client.HTTPConnection.debuglevel = 1
            http.client.HTTPSConnection.debuglevel = 1

    def https_post(self, data):
        """ Post to AMQ Proxy"""
        if self.args.dryrun:
            self.logger.debug('[DRYRUN] Post to %s%s%s. Content: %s', self.args.endpoint,
                              self.args.port, self.args.destination, data)
            return
        # Output data is expected to be list
        if isinstance(data, dict):
            data = [data]
        context = ssl.SSLContext(ssl.PROTOCOL_SSLv23)
        print(self.args.ssl_cert_file, self.args.ssl_key_file)
        context.load_cert_chain(certfile=self.args.ssl_cert_file, keyfile=self.args.ssl_key_file)
        connection = http.client.HTTPSConnection(self.args.endpoint, port=self.args.port, context=context)
        connection.request(method="POST", url=self.args.destination,
                           headers={"Content-Type": 'application/json'},
                           body=json.dumps(data))
        response = connection.getresponse()
        self.logger.info("Post finished. Response: %s %s", response.status, response.reason)


    def reportToAMQProxy(self, action):
        """ Report info to AMQ Proxy """
        payload = {'files': [], 'rse': self.args.rse, 'lifetime': self.args.lifetime, 'operation': action}
        out = self.rucio.validate_files(self.fileOut)
        for item in out['GOOD']:
            fInfo = {'scope': self.args.vo, 'name': item['lfn'],
                     'bytes': item['bytes'], 'adler32': item['adler32']}
            payload['files'].append(fInfo)
        if len(payload['files']) > 0:
            # This can happen that all files are bad, so we only try to report if there are
            # Good files to be reported
            self.rucio.validate_payload(payload)
            self.https_post(payload)
        for item in out['BAD']:
            self.logger.debug('File %s not reported to AMQ proxy. See error message: %s', item['lfn'], item)
        # Only for testing
        #for item in out['BAD']:
        #    fInfo = {'scope': self.args.vo, 'name': item['lfn'],
        #             'bytes': item['bytes'], 'adler32': item['adler32']}
        #    payload['files'].append(fInfo)


    def osCmd(self, command):
        """ Execute shell command """
        self.logger.debug("Execute command: %s", command)
        command = shlex.split(command)
        proc = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        return proc.communicate()

    def getFileInfo(self, cInfoFile):
        """ Get file info. Returns:
          cInfo - content of cInfo file;
          filename - filename (removed root dir and .cinfo ending)
          fOk - if all checks succeeded (file exists, all needed keys available)"""
        cInfo = {}
        # Filename is file on FS itself, which might have prepended path of self.args.rootdir, like /xcache-root
        # In CMS case, lfn they do expect to start with /store
        cInfo['cInfoFile'] = cInfoFile
        cInfo['sysFile'] = cInfoFile[:-6]
        cInfo['lfn'] = cInfoFile[len(self.args.rootdir):-6]
        cInfo['fOk'] = True
        try:
            if not os.path.isfile(cInfo['cInfoFile']):
                cInfo['fOk'] = False
                raise XrdPfcException("%s file does not exist." % cInfo['cInfoFile'])
            if not os.path.isfile(cInfo['sysFile']):
                cInfo['fOk'] = False
                raise XrdPfcException("%s file does not exist." % cInfo['sysFile'])
            if cInfo['fOk']:
                # TODO: This is NEW and build locally! ETA to be released in XRootD 5.4
                # before this release, xrootd is not able to print meta info in JSON format
                # Fix: https://github.com/xrootd/xrootd/pull/1530
                stdOut, _ = self.osCmd('/opt/xrootd/bin/xrdpfc_print -j %s' % cInfoFile)
                cInfo.update(json.loads(stdOut))
                for key in ['state_complete', 'state_percentage', 'file_size']:
                    if key not in cInfo.keys():
                        raise XrdPfcException("%s is not available in cInfo file." % key)
        except (json.decoder.JSONDecodeError, TypeError, XrdPfcException) as ex:
            # json.decoder.JSONDecodeError - bad json
            # TypeError - loading not string object
            self.logger.debug("xrdpfc json print failed. Err: %s", ex)
            cInfo['fOk'] = False
        # Returned filename is without root dir. This is lfn experiment expects
        self.logger.debug('Loaded info from xrootd cinfo file: %s', cInfo)
        return cInfo

    def getAdler(self, fInfo):
        """ Get adler32 - either using local cmd (xrdadler32) or from rucio.
            Returns checksum and metadata.
            In case local (xrdadler32) used, metadata will be empty
            In case rucio used - metadata will be info from Rucio.
            So we dont need to query 2 times Rucio for same file info
        """
        checksum, metadata = None, None
        if self.args.adler == 'local':
            checksum, metadata = self.getChecksumVal(fInfo)
        elif self.args.adler == 'rucio':
            metadata = self.rucio.get_file_metadata(fInfo)
            checksum = metadata['adler32']
        return checksum, metadata

    def getChecksumVal(self, fInfo):
        """ Get Checksum value using xrdadler32 """
        if self.args.dryrun:
            tmpOut = {'adler32': '00000001', 'bytes': fInfo['bytes']}
            self.logger.debug("[DRYRUN]. Return dummy metadata info for file %s. Return %s.", fInfo['lfn'], tmpOut)
            return '00000001', tmpOut
        command = "xrdadler32 %s" % fInfo['sysFile']

        stdOut, _ = self.osCmd(command)
        return stdOut.split()[0].decode('utf-8'), None

    def executeAdd(self, action='add_replicas'):
        """ Prepares dict for add_replicas action and
            report to AMQ Proxy Server. """
        totalFiles = 0
        scandir = "/%s/%s" % (self.args.rootdir.strip('/'), self.args.onlyfilesfromdir.strip('/'))
        self.logger.info("Looping on %s dir and checking all files, cinfo", scandir)
        for root, _dirs, files in os.walk(scandir):
            for fname in files:
                if fname.endswith(".cinfo"):
                    cinfoFile = os.path.join(root, fname)
                    # cInfo - loaded cInfo file output (dict)
                    cInfo = self.getFileInfo(cinfoFile)
                    if cInfo['fOk']:
                        if cInfo['state_complete'] == 'complete' and cInfo['state_percentage'] == 100.0:
                            fInfo = self.fileOut.setdefault(cInfo['lfn'], cInfo)
                            fInfo['bytes'] = fInfo['file_size']
                            try:
                                fInfo['adler32'], fInfo['metadata'] = self.getAdler(fInfo)
                            except DataIdentifierNotFound:
                                # Means this file does not exist in Rucio.
                                del self.fileOut[cInfo['lfn']]  # Removing it from report dict
                                continue
                            totalFiles += 1
                            fInfo['complete'] = True
                        else:
                            self.logger.debug("File %s is partial. Will not report to Rucio", cInfo['lfn'])
                        if len(self.fileOut) >= int(self.args.fileperreport):
                            self.logger.info('Reached %s files per report. Reporting to AMQ Proxy.', self.args.fileperreport)
                            self.reportToAMQProxy(action)
                            self.allfiles.update(self.fileOut)
                            self.fileOut = {}
        if self.fileOut:
            self.logger.info('Reporting remaining files from last scan. Remaining files to report: %s', len(self.fileOut))
            self.reportToAMQProxy(action)
            self.allfiles.update(self.fileOut)
            self.fileOut = {}
        self.logger.info('Finished scan of all files. Total Reported to Rucio: %s', len(self.allfiles))

# This is still unclear what we want to do and there are few options:
# 1. Always do add_replicas with X Lifetime and no delete_replicas
# 2. Always do add_replicas only for new fiels and delete replicas for files registered
#    in Rucio - but physical file not available. This will not work, because on cache
#    each server stores just part of files and not all. So it might happen that
#    xrd-cache-1 reported file /store/foo.root, but xrd-cache-2 runtime fails to find
#    that file on local storage. Is there a better solution to this? Unknown.
# 3. Always do add replicas with X lifetime and update_replicas.
#    Would it be lower cost on Rucio backend to update vs add - to be find out.
#    Also need to find out what happens if it adds file, which was already added.
#    Does it update it, or ignores, or raises error.

    def executeDelete(self, action='delete_replicas'):
        """ Prepares dict for delete_replicas action and
            report to AMQ Proxy Server. """
        raise XCacheReportException("Delete replicas not supported.")

    def executeUpdate(self, action='update_replicas'):
        """ Prepares dict for update_replicas action and
            report to AMQ Proxy Server. """
        raise XCacheReportException("Update replicas not supported.")

def validate_args(args):
    """ Validate arguments """
    # Check port
    try:
        tmpVal = int(args.port)
        if not 0 < tmpVal < 65536:
            raise XCacheArgsException('--port wrong value. TCP Port must be between 1 and 65536.')
    except ValueError:
        raise XCacheArgsException('--port wrong value. Only Integer is supported.') from ValueError

    # destination endpoint must start with /
    if not args.destination.startswith('/'):
        raise XCacheArgsException('--destination wrong value. It must start with /.')

    # Ensure that certificate and certificate-key files are present
    if not os.path.isfile(args.ssl_cert_file):
        raise XCacheArgsException('--certificate file is not present.')
    if not os.path.isfile(args.ssl_key_file):
        raise XCacheArgsException('--certificate-key file is not present.')

    # Ensure adler flag is correct. Only local, rucio are supported
    if args.adler not in ['local', 'rucio']:
        raise XCacheArgsException('--adler flag is not supported.')

    # Ensure root dir is directory
    if not os.path.isdir(args.rootdir):
        raise XCacheArgsException('--root-dir is not a directory.')

    scandir = "/%s/%s" % (args.rootdir.strip('/'), args.onlyfilesfromdir.strip('/'))
    if not os.path.isdir(scandir):
        raise XCacheArgsException('--root-dir + --only-files-from-dir (%s) is not a directory.' % scandir)

    # Rse cant be None. Mandatory to specify
    if not args.rse:
        raise XCacheArgsException('--rse is mandatory to specify.')

    # Check if files-per-report is integer and higher than 0
    try:
        tmpVal = int(args.fileperreport)
        if tmpVal <= 0:
            raise XCacheArgsException('--files-per-report wrong value. Value must be higher than 0')
    except ValueError:
        raise XCacheArgsException('--files-per-report wrong value. Only Integer is supported.') from ValueError

    # Check if lifetime value is integer and higher than 0
    try:
        tmpVal = int(args.lifetime)
        if tmpVal <= 0:
            raise XCacheArgsException('--lifetime wrong value. Value must be higher than 0')
    except ValueError:
        raise XCacheArgsException('--lifetime wrong value. Only Integer is supported.') from ValueError

    # Check if debug flag supported.
    if args.debug not in ['FATAL', 'ERROR', 'WARNING', 'INFO', 'DEBUG']:
        raise XCacheArgsException('--debug wrong value. It is not in supported list of options.')

def get_parser():
    """
    Returns the argparse parser.
    """
    # pylint: disable=line-too-long
    oparser = argparse.ArgumentParser(description="This daemons is used to populate information of replicas on volatile storage.",
                                      prog=os.path.basename(sys.argv[0]), add_help=True)
    # Main arguments
    oparser.add_argument('--endpoint', dest='endpoint', default=config_get('messaging-cache', 'endpoint'), help='Endpoint hostname')
    oparser.add_argument('--port', dest='port', default=config_get_int('messaging-cache', 'port'), help='Endpoint port')
    oparser.add_argument('--destination', dest='destination', default=config_get('messaging-cache', 'destination'), help="URL Destination to send message to")
    oparser.add_argument('--vo', dest='vo', default=config_get('messaging-cache', 'vo'), help='VO Name')
    oparser.add_argument('--certificate', dest='ssl_cert_file', default=config_get('messaging-cache', 'ssl_cert_file', False, os.environ['X509_USER_PROXY']), help='Certificate file. Default: X509_USER_PROXY')
    oparser.add_argument('--certificate-key', dest='ssl_key_file', default=config_get('messaging-cache', 'ssl_key_file', False, os.environ['X509_USER_PROXY']), help='Certificate key file. Default: X509_USER_PROXY')
    oparser.add_argument('--dry-run', dest='dryrun', default=config_get_bool('messaging-cache', 'dryrun', False), help="Dry Run. No reporting to endpoint. Default: False", action='store_true')
    oparser.add_argument('--adler', dest='adler', default=config_get('messaging-cache', 'adler', 'local'), help="Adler calculation: local | rucio. Default: local")
    oparser.add_argument('--root-dir', dest='rootdir', default=config_get('messaging-cache', 'rootdir'), help="XCache Root Directory")
    oparser.add_argument('--only-files-from-dir', dest='onlyfilesfromdir', default=config_get('messaging-cache', 'onlyfilesfromdir', False, '/'), help="Report only specific dir files")
    oparser.add_argument('--rse', dest='rse', default=None, help="Volatile RSE Name")
    oparser.add_argument('--files-per-report', dest='fileperreport', default=config_get_int('messaging-cache', 'fileperreport', 100), help="How many files to group in a single report. Default: 100")
    oparser.add_argument('--lifetime', dest='lifetime', default=config_get_int('messaging-cache', 'lifetime', 604800), help="Lifetime of a file. Default: 604800 seconds (1 week)")
    oparser.add_argument('--debug', dest='debug', default=config_get('messaging-cache', 'debug', False, 'INFO'), help="Debug mode. Available options: FATAL,ERROR,WARNING,INFO,DEBUG. Default: INFO")
    return oparser

def main(args, inLogger):
    """ Main call """
    scanner = CacheWorker(args, inLogger)
    scanner.executeAdd()

if __name__ == "__main__":
    parser = get_parser()
    if len(sys.argv) == 1:
        parser.print_help()

    inargs = parser.parse_args(sys.argv[1:])
    validate_args(inargs)
    streamLogger = getLogger(logLevel=inargs.debug, streamLogging=True)
    main(inargs, streamLogger)
